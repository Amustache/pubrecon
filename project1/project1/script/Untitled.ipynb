{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    \"\"\"\n",
    "    Standardize the original data set.\n",
    "\n",
    "    :param x: Data set.\n",
    "    :return: Standardized data set.\n",
    "    \"\"\"\n",
    "    mean_x = np.mean(x, axis=0)\n",
    "    x = x - mean_x\n",
    "    std_x = np.std(x, axis=0)\n",
    "    x = x / std_x\n",
    "    return x, mean_x, std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, tX_mean, tX_std = standardize(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[1]):\n",
    "    data[:, i][np.where(data[:,i] == -999)] = tX_mean[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.13221613e-01,  6.83319669e-02,  4.07680272e-01, ...,\n",
       "         1.13612250e+00, -2.52828975e+00,  4.12510497e-01],\n",
       "       [ 8.40891468e-01,  5.52504823e-01,  5.40136414e-01, ...,\n",
       "         3.14052005e-03,  4.69108779e-04, -2.73819964e-01],\n",
       "       [-1.50629345e+00,  3.19515553e+00,  1.09655998e+00, ...,\n",
       "         3.14052005e-03,  4.69108779e-04, -2.93969845e-01],\n",
       "       ...,\n",
       "       [ 3.17436708e-02,  3.19316447e-01, -1.30863670e-01, ...,\n",
       "         3.14052005e-03,  4.69108779e-04, -3.17017229e-01],\n",
       "       [-1.21481036e-01, -8.45323970e-01, -3.02973380e-01, ...,\n",
       "         3.14052005e-03,  4.69108779e-04, -7.45439413e-01],\n",
       "       [-1.50629345e+00,  6.65336083e-01, -2.53522760e-01, ...,\n",
       "         3.14052005e-03,  4.69108779e-04, -7.45439413e-01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[138.47 ,  51.655,  97.827, ...,   1.24 ,  -2.475, 113.497],\n",
       "       [160.937,  68.768, 103.235, ...,   0.   ,   0.   ,  46.226],\n",
       "       [  0.   , 162.172, 125.953, ...,   0.   ,   0.   ,  44.251],\n",
       "       ...,\n",
       "       [105.457,  60.526,  75.839, ...,   0.   ,   0.   ,  41.992],\n",
       "       [ 94.951,  19.362,  68.812, ...,   0.   ,   0.   ,   0.   ],\n",
       "       [  0.   ,  72.756,  70.831, ...,   0.   ,   0.   ,   0.   ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(y, tx, batch_size, num_batches=1, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generate a minibatch iterator for a dataset.\n",
    "    Takes as input two iterables (here the output desired values 'y' and the input data 'tx')\n",
    "    Outputs an iterator which gives mini-batches of `batch_size` matching elements from `y` and `tx`.\n",
    "    Data can be randomly shuffled to avoid ordering in the original data messing with the randomness of the minibatches.\n",
    "    Example of use :\n",
    "    for minibatch_y, minibatch_tx in batch_iter(y, tx, 32):\n",
    "        <DO-SOMETHING>\n",
    "\n",
    "    :param y: Labels.\n",
    "    :param tx: Features.\n",
    "    :param batch_size: Size of the batch.\n",
    "    :param num_batches: Number of batches.\n",
    "    :param shuffle: Should the data be shuffled?\n",
    "    :return: Batch iterator.\n",
    "    \"\"\"\n",
    "    data_size = len(y)\n",
    "\n",
    "    if shuffle:\n",
    "        shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "        shuffled_y = y[shuffle_indices]\n",
    "        shuffled_tx = tx[shuffle_indices]\n",
    "    else:\n",
    "        shuffled_y = y\n",
    "        shuffled_tx = tx\n",
    "    for batch_num in range(num_batches):\n",
    "        start_index = batch_num * batch_size\n",
    "        end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "        if start_index != end_index:\n",
    "            yield shuffled_y[start_index:end_index], shuffled_tx[start_index:end_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Gradient descent algorithm.\n",
    "\n",
    "    :param y: Labels.\n",
    "    :param tx: Features.\n",
    "    :param initial_w: Initial weight vector.\n",
    "    :param max_iters: Number of steps to run.\n",
    "    :param gamma: Step-size.\n",
    "    :return:`(w, loss)`, with `w` the last weight vector of the method, and `loss` the corresponding loss value (cost function).\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    w = initial_w\n",
    "    prev_err = float('inf')\n",
    "    for n_iter in range(max_iters):\n",
    "        # Transpose the features\n",
    "        y_pred = np.sign(tx.dot(w))\n",
    "        \n",
    "        loss = y_pred - y\n",
    "        \n",
    "        error = (loss ** 2).mean()\n",
    "        \n",
    "        if error >= prev_err:\n",
    "            error = prev_err\n",
    "            break\n",
    "        else:\n",
    "            prev_err = error\n",
    "        \n",
    "        grad = (1. / tx.shape[0]) * tx.T.dot(loss)\n",
    "        \n",
    "        w = w - gamma * grad\n",
    "        \n",
    "        print(\"Iter {} of {}. Error: {}\".format(n_iter + 1, max_iters, error))\n",
    "    return w, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.random.random(tX.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1 of 150. Error: 1.492208\n",
      "Iter 2 of 150. Error: 1.492208\n",
      "Iter 3 of 150. Error: 1.492192\n",
      "Iter 4 of 150. Error: 1.492176\n",
      "Iter 5 of 150. Error: 1.492176\n",
      "Iter 6 of 150. Error: 1.49216\n",
      "Iter 7 of 150. Error: 1.492144\n",
      "Iter 8 of 150. Error: 1.492112\n",
      "Iter 9 of 150. Error: 1.492064\n",
      "Iter 10 of 150. Error: 1.492064\n",
      "Iter 11 of 150. Error: 1.492048\n",
      "Iter 12 of 150. Error: 1.492032\n",
      "Iter 13 of 150. Error: 1.492016\n",
      "Iter 14 of 150. Error: 1.492016\n",
      "Iter 15 of 150. Error: 1.492016\n",
      "Iter 16 of 150. Error: 1.492016\n",
      "Iter 17 of 150. Error: 1.491968\n",
      "Iter 18 of 150. Error: 1.491952\n",
      "Iter 19 of 150. Error: 1.491936\n",
      "Iter 20 of 150. Error: 1.49192\n",
      "Iter 21 of 150. Error: 1.491904\n",
      "Iter 22 of 150. Error: 1.491888\n",
      "Iter 23 of 150. Error: 1.49184\n",
      "Iter 24 of 150. Error: 1.491808\n",
      "Iter 25 of 150. Error: 1.491808\n",
      "Iter 26 of 150. Error: 1.491808\n",
      "Iter 27 of 150. Error: 1.49176\n",
      "Iter 28 of 150. Error: 1.491712\n",
      "Iter 29 of 150. Error: 1.49168\n",
      "Iter 30 of 150. Error: 1.491648\n",
      "Iter 31 of 150. Error: 1.491648\n",
      "Iter 32 of 150. Error: 1.491536\n",
      "Iter 33 of 150. Error: 1.491488\n",
      "Iter 34 of 150. Error: 1.49144\n",
      "Iter 35 of 150. Error: 1.491424\n",
      "Iter 36 of 150. Error: 1.491344\n",
      "Iter 37 of 150. Error: 1.491328\n",
      "Iter 38 of 150. Error: 1.49128\n",
      "Iter 39 of 150. Error: 1.491264\n",
      "Iter 40 of 150. Error: 1.491248\n",
      "Iter 41 of 150. Error: 1.491248\n",
      "Iter 42 of 150. Error: 1.4912\n",
      "Iter 43 of 150. Error: 1.491168\n",
      "Iter 44 of 150. Error: 1.491136\n",
      "Iter 45 of 150. Error: 1.491104\n",
      "Iter 46 of 150. Error: 1.491024\n",
      "Iter 47 of 150. Error: 1.49096\n",
      "Iter 48 of 150. Error: 1.490912\n",
      "Iter 49 of 150. Error: 1.490832\n",
      "Iter 50 of 150. Error: 1.490816\n",
      "Iter 51 of 150. Error: 1.490768\n",
      "Iter 52 of 150. Error: 1.490704\n",
      "Iter 53 of 150. Error: 1.49064\n",
      "Iter 54 of 150. Error: 1.490576\n",
      "Iter 55 of 150. Error: 1.49048\n",
      "Iter 56 of 150. Error: 1.4904\n",
      "Iter 57 of 150. Error: 1.49032\n",
      "Iter 58 of 150. Error: 1.490272\n",
      "Iter 59 of 150. Error: 1.490224\n",
      "Iter 60 of 150. Error: 1.490192\n",
      "Iter 61 of 150. Error: 1.490128\n",
      "Iter 62 of 150. Error: 1.490096\n",
      "Iter 63 of 150. Error: 1.490016\n",
      "Iter 64 of 150. Error: 1.489984\n",
      "Iter 65 of 150. Error: 1.48976\n",
      "Iter 66 of 150. Error: 1.489696\n",
      "Iter 67 of 150. Error: 1.489616\n",
      "Iter 68 of 150. Error: 1.489552\n",
      "Iter 69 of 150. Error: 1.489472\n",
      "Iter 70 of 150. Error: 1.48928\n",
      "Iter 71 of 150. Error: 1.489168\n",
      "Iter 72 of 150. Error: 1.489072\n",
      "Iter 73 of 150. Error: 1.488816\n",
      "Iter 74 of 150. Error: 1.48856\n",
      "Iter 75 of 150. Error: 1.488528\n",
      "Iter 76 of 150. Error: 1.488352\n",
      "Iter 77 of 150. Error: 1.488096\n",
      "Iter 78 of 150. Error: 1.488\n",
      "Iter 79 of 150. Error: 1.487952\n",
      "Iter 80 of 150. Error: 1.487824\n",
      "Iter 81 of 150. Error: 1.487616\n",
      "Iter 82 of 150. Error: 1.487344\n",
      "Iter 83 of 150. Error: 1.487168\n",
      "Iter 84 of 150. Error: 1.486928\n",
      "Iter 85 of 150. Error: 1.486912\n",
      "Iter 86 of 150. Error: 1.486592\n",
      "Iter 87 of 150. Error: 1.486512\n",
      "Iter 88 of 150. Error: 1.486432\n",
      "Iter 89 of 150. Error: 1.48608\n",
      "Iter 90 of 150. Error: 1.485792\n",
      "Iter 91 of 150. Error: 1.485248\n",
      "Iter 92 of 150. Error: 1.485024\n",
      "Iter 93 of 150. Error: 1.48448\n",
      "Iter 94 of 150. Error: 1.484144\n"
     ]
    }
   ],
   "source": [
    "loss, w = gradient_descent(y, tX, initial_w, 150, .00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.484144"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.sign(tX.dot(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32400 127131 37202 53267\n"
     ]
    }
   ],
   "source": [
    "TP = np.sum(np.logical_and(y_pred == 1, y == 1))\n",
    "TN = np.sum(np.logical_and(y_pred == -1, y == -1))\n",
    "FP = np.sum(np.logical_and(y_pred == 1, y == -1))\n",
    "FN = np.sum(np.logical_and(y_pred == -1, y == 1))\n",
    "print(TP, TN, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4655038648314704"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37820864510254826"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = TP / (TP + FN)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2263817979346814"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FPR = FP / (FP + TN)\n",
    "FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.638124"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4173402288930824"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best value at 1\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stoch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent algorithm.\n",
    "\n",
    "    :param y: Predictions.\n",
    "    :param tx: Target.\n",
    "    :param initial_w: Initial weight vector.\n",
    "    :param batch_size: Size of the batch.\n",
    "    :param max_iters: Number of steps to run.\n",
    "    :param gamma: Step-size.\n",
    "    :return:`(w, loss)`, with `w` the last weight vector of the method, and `loss` the corresponding loss value (cost function).\n",
    "    \"\"\"\n",
    "    w = initial_w\n",
    "    prev_err = float('inf')\n",
    "    for n_iter in range(max_iters):\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size=batch_size):\n",
    "            y_pred = np.sign(minibatch_tx.dot(w))\n",
    "        \n",
    "            loss = y_pred - minibatch_y\n",
    "\n",
    "            error = (loss ** 2).mean()\n",
    "\n",
    "            if error >= prev_err:\n",
    "                error = prev_err\n",
    "                break\n",
    "            else:\n",
    "                prev_err = error\n",
    "\n",
    "            grad = (1. / minibatch_tx.shape[0]) * minibatch_tx.T.dot(loss)\n",
    "\n",
    "            w = w - gamma * grad\n",
    "        \n",
    "        print(\"Iter {} of {}. Error: {}\".format(n_iter + 1, max_iters, error))\n",
    "    return w, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.random.random(tX.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1 of 150. Error: 1.609375\n",
      "Iter 2 of 150. Error: 1.46875\n",
      "Iter 3 of 150. Error: 1.390625\n",
      "Iter 4 of 150. Error: 1.375\n",
      "Iter 5 of 150. Error: 1.375\n",
      "Iter 6 of 150. Error: 1.375\n",
      "Iter 7 of 150. Error: 1.375\n",
      "Iter 8 of 150. Error: 1.375\n",
      "Iter 9 of 150. Error: 1.375\n",
      "Iter 10 of 150. Error: 1.375\n",
      "Iter 11 of 150. Error: 1.375\n",
      "Iter 12 of 150. Error: 1.375\n",
      "Iter 13 of 150. Error: 1.375\n",
      "Iter 14 of 150. Error: 1.375\n",
      "Iter 15 of 150. Error: 1.375\n",
      "Iter 16 of 150. Error: 1.375\n",
      "Iter 17 of 150. Error: 1.375\n",
      "Iter 18 of 150. Error: 1.296875\n",
      "Iter 19 of 150. Error: 1.25\n",
      "Iter 20 of 150. Error: 1.25\n",
      "Iter 21 of 150. Error: 1.25\n",
      "Iter 22 of 150. Error: 1.25\n",
      "Iter 23 of 150. Error: 1.25\n",
      "Iter 24 of 150. Error: 1.25\n",
      "Iter 25 of 150. Error: 1.25\n",
      "Iter 26 of 150. Error: 1.25\n",
      "Iter 27 of 150. Error: 1.25\n",
      "Iter 28 of 150. Error: 1.25\n",
      "Iter 29 of 150. Error: 1.25\n",
      "Iter 30 of 150. Error: 1.25\n",
      "Iter 31 of 150. Error: 1.25\n",
      "Iter 32 of 150. Error: 1.25\n",
      "Iter 33 of 150. Error: 1.171875\n",
      "Iter 34 of 150. Error: 1.171875\n",
      "Iter 35 of 150. Error: 1.171875\n",
      "Iter 36 of 150. Error: 1.171875\n",
      "Iter 37 of 150. Error: 1.171875\n",
      "Iter 38 of 150. Error: 1.171875\n",
      "Iter 39 of 150. Error: 1.171875\n",
      "Iter 40 of 150. Error: 1.171875\n",
      "Iter 41 of 150. Error: 1.171875\n",
      "Iter 42 of 150. Error: 1.171875\n",
      "Iter 43 of 150. Error: 1.171875\n",
      "Iter 44 of 150. Error: 1.171875\n",
      "Iter 45 of 150. Error: 1.171875\n",
      "Iter 46 of 150. Error: 1.171875\n",
      "Iter 47 of 150. Error: 1.171875\n",
      "Iter 48 of 150. Error: 1.171875\n",
      "Iter 49 of 150. Error: 1.171875\n",
      "Iter 50 of 150. Error: 1.171875\n",
      "Iter 51 of 150. Error: 1.171875\n",
      "Iter 52 of 150. Error: 1.171875\n",
      "Iter 53 of 150. Error: 1.171875\n",
      "Iter 54 of 150. Error: 1.171875\n",
      "Iter 55 of 150. Error: 1.171875\n",
      "Iter 56 of 150. Error: 1.171875\n",
      "Iter 57 of 150. Error: 1.171875\n",
      "Iter 58 of 150. Error: 1.171875\n",
      "Iter 59 of 150. Error: 1.171875\n",
      "Iter 60 of 150. Error: 1.171875\n",
      "Iter 61 of 150. Error: 1.171875\n",
      "Iter 62 of 150. Error: 1.171875\n",
      "Iter 63 of 150. Error: 1.171875\n",
      "Iter 64 of 150. Error: 1.171875\n",
      "Iter 65 of 150. Error: 1.171875\n",
      "Iter 66 of 150. Error: 1.171875\n",
      "Iter 67 of 150. Error: 1.171875\n",
      "Iter 68 of 150. Error: 1.171875\n",
      "Iter 69 of 150. Error: 1.171875\n",
      "Iter 70 of 150. Error: 1.171875\n",
      "Iter 71 of 150. Error: 1.171875\n",
      "Iter 72 of 150. Error: 1.171875\n",
      "Iter 73 of 150. Error: 1.171875\n",
      "Iter 74 of 150. Error: 1.171875\n",
      "Iter 75 of 150. Error: 1.171875\n",
      "Iter 76 of 150. Error: 1.171875\n",
      "Iter 77 of 150. Error: 1.171875\n",
      "Iter 78 of 150. Error: 1.171875\n",
      "Iter 79 of 150. Error: 1.171875\n",
      "Iter 80 of 150. Error: 1.171875\n",
      "Iter 81 of 150. Error: 1.171875\n",
      "Iter 82 of 150. Error: 1.171875\n",
      "Iter 83 of 150. Error: 1.171875\n",
      "Iter 84 of 150. Error: 1.171875\n",
      "Iter 85 of 150. Error: 1.171875\n",
      "Iter 86 of 150. Error: 1.171875\n",
      "Iter 87 of 150. Error: 1.171875\n",
      "Iter 88 of 150. Error: 1.171875\n",
      "Iter 89 of 150. Error: 1.171875\n",
      "Iter 90 of 150. Error: 1.171875\n",
      "Iter 91 of 150. Error: 1.171875\n",
      "Iter 92 of 150. Error: 1.171875\n",
      "Iter 93 of 150. Error: 1.171875\n",
      "Iter 94 of 150. Error: 1.171875\n",
      "Iter 95 of 150. Error: 1.171875\n",
      "Iter 96 of 150. Error: 1.171875\n",
      "Iter 97 of 150. Error: 1.171875\n",
      "Iter 98 of 150. Error: 1.171875\n",
      "Iter 99 of 150. Error: 1.171875\n",
      "Iter 100 of 150. Error: 1.171875\n",
      "Iter 101 of 150. Error: 1.171875\n",
      "Iter 102 of 150. Error: 1.171875\n",
      "Iter 103 of 150. Error: 1.171875\n",
      "Iter 104 of 150. Error: 1.171875\n",
      "Iter 105 of 150. Error: 1.171875\n",
      "Iter 106 of 150. Error: 1.171875\n",
      "Iter 107 of 150. Error: 1.171875\n",
      "Iter 108 of 150. Error: 1.171875\n",
      "Iter 109 of 150. Error: 1.171875\n",
      "Iter 110 of 150. Error: 1.171875\n",
      "Iter 111 of 150. Error: 1.171875\n",
      "Iter 112 of 150. Error: 1.171875\n",
      "Iter 113 of 150. Error: 1.171875\n",
      "Iter 114 of 150. Error: 1.171875\n",
      "Iter 115 of 150. Error: 1.171875\n",
      "Iter 116 of 150. Error: 1.171875\n",
      "Iter 117 of 150. Error: 1.171875\n",
      "Iter 118 of 150. Error: 1.171875\n",
      "Iter 119 of 150. Error: 1.171875\n",
      "Iter 120 of 150. Error: 1.171875\n",
      "Iter 121 of 150. Error: 1.171875\n",
      "Iter 122 of 150. Error: 1.171875\n",
      "Iter 123 of 150. Error: 1.171875\n",
      "Iter 124 of 150. Error: 1.171875\n",
      "Iter 125 of 150. Error: 1.171875\n",
      "Iter 126 of 150. Error: 1.171875\n",
      "Iter 127 of 150. Error: 1.171875\n",
      "Iter 128 of 150. Error: 1.171875\n",
      "Iter 129 of 150. Error: 1.171875\n",
      "Iter 130 of 150. Error: 1.171875\n",
      "Iter 131 of 150. Error: 1.171875\n",
      "Iter 132 of 150. Error: 1.171875\n",
      "Iter 133 of 150. Error: 1.171875\n",
      "Iter 134 of 150. Error: 1.171875\n",
      "Iter 135 of 150. Error: 1.171875\n",
      "Iter 136 of 150. Error: 1.171875\n",
      "Iter 137 of 150. Error: 1.171875\n",
      "Iter 138 of 150. Error: 1.171875\n",
      "Iter 139 of 150. Error: 1.171875\n",
      "Iter 140 of 150. Error: 1.171875\n",
      "Iter 141 of 150. Error: 1.171875\n",
      "Iter 142 of 150. Error: 1.171875\n",
      "Iter 143 of 150. Error: 1.171875\n",
      "Iter 144 of 150. Error: 1.171875\n",
      "Iter 145 of 150. Error: 1.171875\n",
      "Iter 146 of 150. Error: 1.171875\n",
      "Iter 147 of 150. Error: 1.171875\n",
      "Iter 148 of 150. Error: 1.171875\n",
      "Iter 149 of 150. Error: 1.171875\n",
      "Iter 150 of 150. Error: 1.171875\n"
     ]
    }
   ],
   "source": [
    "w, loss = stochastic_gradient_descent(y, tX, initial_w, 256, 150, .0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/output.csv'\n",
    "y_pred = predict_labels(w, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
