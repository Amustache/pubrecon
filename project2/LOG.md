# LOGBOOK

## 2019.12.19
- Bla bla rush final okay bon.
- For the record: j'ai essay√© talos et hyperas mais √ßa marche moyen avec mon impl√©mentation.
- Faut explorer https://github.com/fizyr/keras-retinanet aussi.

## 2019.12.18
- Test du mod√®le sur un autre ordinateur. On se rend compte que si tensorflow-gpu est disponible, le mod√®le ne fonctionne pas.
    - cf. https://github.com/matterport/Mask_RCNN/wiki notamment.
- Nettoyage des notebooks pour ne garder qu'un exemple utile.
- Fix de dependencies et de typos, ainsi qu'une GROSSE erreur dans le mod√®le.
- On laisse tourner le learning "pour voir".
- Prochaines √©tapes importantes :
    - Cross-validation, hyperparameters, toussa.
    - Tester et retester que le package fonctionne sur un ordinateur lambda.
    - (Optionnel) Impl√©menter le GPU (ja-mais on aura le temps).
    - Dump des liens qui trainent, √† lire et √† trier : https://pastebin.com/jBDxGhhH (oui c'est long)
    - ! Terminer le rapport !
    - Mettre quelques datas disponibles en ligne pour que les gens puissent tester.
    - Rappel des trucs √† am√©liorer pour le PDF/code d'apr√®s le projet 1:
        - cross-validation is used to tune the hyperparameters
        - you do not have any test vs train leanring curves
        - you do not tune the hyperparameters
        - [do preprocessing]
        - you do not compare any models
        - you do not have baselines (=What is the hypothesis?)
- Ajout du mode batch pour acc√©l√©rer le mod√®le.

## 2019.12.17
- Travail sur le rapport.
- Travail sur le packaging.
    - Il devrait √™tre termin√©.
- R√©sultats du mod√®le pour 100 samples et 10 epochs, 76.6% d'accuracy.
- Question sur la vitesse.
    - Il faudrait voir pour optimiser le selective search.
- Travail sur le c√¥t√© "tuto".

## 2019.12.16
- Travail sur le rapport.
- Travail sur le packaging.

## 2019.12.15
- "Je _crois_ que j'ai un truc qui fonctionne."
- (Petit/Gros) R√©sum√© :
    - Je commence par r√©cup√©rer toutes les photos/labels et je les mets dans une dataframe pandas. Je sauvegarde le tout pour pas se faire ***** √† chaque fois.
    - Pour chaque image, je r√©cup√®re des "areas of interest" avec le selective search de cv2.
    - A partir de ces aoi, je compare avec le ground truth ("les vrais labels") pour voir si √ßa colle suivant un threeshold. Si c'est le cas, on l'ajoute √† notre liste de labels, sinon, c'est du background.
    - Ensuite, je construis mon mod√®le. VGG16 pretrained avec des poids de ImageNet, puis je pars du principe que mon r√©seau est d√©j√† entrain√© correctement (flaw: on a pas mal de texte, donc pas forc√©ment que des images), donc je ne r√©entraine que les derniers layers.
    - Ensuite, √ßa part en entrainement, avec 10% de tests.
    - "Pour √™tre honn√™te j'utilise un RCNN car j'ai r√©ussi √† le faire fonctionner, et VGG dans la structure du RCNN car c'est disponible ^^" - https://www.quora.com/What-is-the-VGG-neural-network
- Totalit√© des donn√©es disponibles: environ 4Go.
    - Par contre du coup c'est la mort pour le learning, y'a bien trop de donn√©es et pas assez de RAM.
    - R√©flexion pour utiliser Google Collab ou Google Cloud.
    - Utiliser du Python "pur" au lieu du Notebook.
    - Optimiser la structure, particuli√®rement le selective search.
- D√©but du packaging.

## 2019.12.13
- Une pr√©sentation "finale" est possible, cela peut √™tre cool d'y aller.

## 2019.12.10
- Objectifs :
    - Terminer le mod√®le, de l'entra√Æner sur Gen4.
    - Avancer le rapport.

## 2019.12.09
- Gen4 enti√®rement lab√©lis√© et disponible.
- ResNet fonctionnel disponible, mais √† tester.
- "Je note √ßa l√† sinon je vais oublier : il faudra parler du fait que nos donn√©es brutes n'ont pas de texte int√©gr√©, que des solutions existent, mais que ce n'√©tait pas le but"

## 2019.12.06
- More data available thanks to Magalie.
- On va restreindre notre √©tude sur Gen4, car pas le temps de lab√©liser plus de trucs.

## 2019.12.04
- Les classes sont disponibles.
    - Il faut faire attention de ne pas avoir un truc d√©pendant du texte, mais seulement du format du texte, car on fait de la reconnaissance d'image, pas de la contextualisation de texte.

## 2019.12.03
- More data available thanks to Magalie.

## 2019.12.02
- Il peut √™tre int√©ressant de contacter Boris Krywicki (Universit√© de Li√®ge).
        
## 2019.12.01
- Travail sur l'impl√©mentation de keras-frcnn.
- Il nous reste moins de trois semaines, y'a du taf.
- Je vais tenter de terminer l'impl√©mentation du mod√®le pr√©-existant. Derri√®re, il faudra le r√©impl√©menter par nous-m√™me si √ßa fonctionne.
    - Ajout de `https://github.com/kbardool/keras-frcnn.git` comme submodule.
- **Note** Selon les impl√©mentations, les bndboxes ne sont pas d√©finies de la m√™me mani√®res (soit par position relative (pixels) soit c'est mapp√© sur [0;1]).
- A priori, notre travail est """exclusif""", dans le sens on n'a pas connaissance de travail similaire.
    - https://www.konbini.com/fr/inspiration-2/30ans-publicites-jeux-video/.
- Le rapport a √©t√© bien avanc√© avec les "grosses parties" pr√©sentes.
- **Note** Lors de la comparaison des r√©sultats, il faudra bien faire attention d'utiliser les m√™mes m√©thodes d'√©valuation que dans le paper d'origine.
    - Paper en question: https://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks.pdf
- On a le p'tit script de conversion pour adapter les XML √† nos mod√®les.
- On travaille sur le FerRCNN, mais c'est CHAUD.
- On travaille sur le rapport.
- R√©flexion au niveau des classes.
    - Au niveau des classes, j'ai p't'√™tre un peu peur que ce soit trop large, mais aucune id√©e
    - Like, on va peut-√™tre devoir s√©lectionner un sous-groupe des classes que tu as propos√©
    - Plus la redondance, si t'as une classe trop "large" (=publicit√© pleine page) sachant que le but c'est reconna√Ætre une publicit√©, ben, le learning risque d'avoir du mal
    - Le but c'est "Ah, y'a une grosse image et peu de texte => proba(pub) √©lev√©e" vs. "Ah, y'a du texte et peu d'image => proba(pub) basse"
    - Alors que si on a toute la page classifi√©e comme "c'est une pub", j'ai aucune id√©e de l'influence
    - Apr√®s, c'est totalement une hypoth√®se !
    - Une autre solution qui existe, c'est effectivement de dire "√ßa c'est pub" "√ßa c'est pas pub" et de laisser le mod√®le faire ses propres classes
    - Id√©alement on tente les deux

## 2019.11.30
- Exploration des datas.
- Les inputs nous sont donn√©es sous format XML. Il faut donc r√©aliser une conversion pr√©liminaire XML > Format que l'on souhaite.
- L'id√©e est de r√©aliser une dataframe pandas pour faciliter l'exploitation, puis de sauvegarder le fichier sous forme de pickle r√©utilisable. Il faut ainsi cr√©er un script de conversion.
    - Script de conversion cr√©√© sous la forme d'un notebook.
- Une fois les datas exploitables, il faut... les exploiter.
    - En gros, utiliser https://github.com/kbardool/keras-frcnn.
        - **Note** Un trick que j'ai appris c'est d'exploiter un mod√®le d√©j√† existant, de "couper" les derniers layers, et de retrain juste sur ces derniers layers. 'peut nous faire gagner du temps.

## 2019.11.26
### Discussion avec Yannick
- Faire attention au niveau de la chronographie
- Pas m√™me classification suivant la p√©riode
- Regarder dans le zip pr√©liminaire
- Ce que l'on a c'est une hypoth√®se pr√©liminaire, changement de direction car pas obligation
- Attente mutuelle
- Prochaines √©tapes :
    - Reconnaissance des datas
    - Identifier le corpus
    - Toy mod√®le
    - Voir ce que √ßa donne
- Pr√©voir un calendrier des √©tapes
- V√©rifier ce que l'on a le droit de r√©utiliser dans le cadre du cours
- Avoir un premier proto
- Iterer sur les erreurs

## 2019.11.25
- R√©ception des premi√®res datas üéâ

## 2019.11.24
- Objectifs de la semaine prochaine (propos√©) :
    - Commencer et bien avancer le rapport.
    - Travailler sur le mod√®le propos√© cf. https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/.
    - Etudier et comparer d'autres mod√®les.

## 2019.11.21
- Il faut r√©duire le corpus.
- Magalie: "Si on prend par exemple Tilt, Joystick hebdo, Joystick (que j'avais tr√®s bizarremet oubli√© dans la bdd) et Gen4 sur 88-98 sans les hors-s√©ries on a 326 num√©ros num√©ris√©s (il manque 3 Gen4), avec une trentaine de num√©ros √† labelliser avec 15/20 classes en comptant 120 pages en moyenne  j'aurai 3600 pages √† labelliser, ce qui devrait me prendre une semaine je pense"
- 

## 2019.11.20
- Arr√™t de la probl√©matique technique: Classification du contenu de pages de magazines.
- Arr√™t de la probl√©matique de recherche: La _place_ (physique et conceptuelle) de la publicit√© dans les magazines de jeu vid√©o.
    - Possibilit√© d'ouverture : La place du contenu √©ditorial par rapport √† la publicit√©.

## 2019.11.19
### Yannick
- "Donc en effet, vous allez construire la probl√©matique en croisant les id√©es de Magalie avec les miennes avec ce qui vous branche en g√©n√©ral. Pour √ßa, je vous recommande d'aller fl√¢ner un peu dans les pages de ces magazines, de vous y perdre quelques heures. Certains magazines sont beaucoup plus c√©l√®bres que d'autres, mais ce peut aussi √™tre l'occasion de faire une analyse de la presse de seconde zone. Tout est possible, depuis l'exploratoire (o√π la probl√©matique devient surtout ax√©e m√©thodo) √† la v√©ritable question de recherche en sciences humaines (o√π la m√©thodologie n'est plus une finalit√©)."
- "Essayez d'avoir une piste aujourd'hui ou demain, et d'avoir une id√©e claire d'ici la fin de la semaine ;-)"
- Lecture obligatoire: https://orbi.uliege.be/bitstream/2268/215516/1/DozoKrywickiArmandColin.pdf
- Lecture recommand√©e: https://goutarcade.hypotheses.org/80
- Attention, pas tous les titres sont correctement scann√©s/trouvables.

### Stache
- Apr√®s m'√™tre un peu balad√© sur AbandonWareMag, il s'est av√©r√© que pamal de "morceaux choisis" n'√©taient pas forc√©ment complets... Donc, pas forc√©ment facile √† traiter
- En revanche, parmi certaines collection, c'est chouette, car il est possible de bien s'amuser !
- Il sera par contre peut-√™tre difficile de r√©aliser des √©tudes sur des magazines "r√©cents", dans le sens que, soit le copyhammer est pr√©sent, soit le magazine n'est pas encore disponible en ligne
- Quelque chose qui resort, c'est qu'au niveau des publicit√©s, ce qui prime, c'est la pleine page
- Un truc qui pourrait √™tre int√©ressant √† √©tudier, c'est de voir la "place" de la publicit√©. Plut√¥t au d√©but ? Plut√¥t √† la fin ? La quantit√© ? etc
- Donc voil√†, est-ce que quelque chose dans la veine de "De l'√©volution de la place de la publicit√© dans la presse sp√©cialis√©e des ann√©es 90 aux ann√©es 2010" vous irait ?
- (Place litt√©rale comme figur√©e, donc)
- *Pourquoi cette p√©riode ?*
    - Compliqu√© de trouver des r√©f√©rences que l'on peut suivre.
    - Apr√®s 2010, soit copystrike, soit pas d'exemplaire.
    - Comme cas d'√©tudes, on peut par exemple utiliser "Player One" ou "Joystick".
- *Pourquoi la place ?*
    - "Type" de publicit√© est assez standardis√©, avec une (deux) pleine(s) page(s), pas r√©guli√®rement des encarts sp√©cifiques, et semble typ√©.
- Notre partie "ML" serait la classification "Pub"/"Pas pub", et notre partie "ADA" serait la place de ladite pub.

## 2019.11.18
- Choix du format √† d√©finir (xml ? json ?)
- *Discussion avec Yannick*
    - Comment faire un "paper":
        - Poser une question de recherche;
            - -> Intro
        - State-of-the-art, qu'est-ce qui existe
            - -> Parler de ce que c'est
            - -> D√©crire les √©l√©ments (ML, DeepL, etc.) et analyser les discours, remettre en contexte, etc.
        - M√©thodologie par rapport √† la probl√©matique
        - Analyse
        - R√©sultats
        - Conclusion
    - Profiter du site https://abandonware-magazines.org/
        - Scans de magazines
        - URLs et noms coh√©rents, mais pas toujours
            - -> Besoin d'un peu de data concierge
        - Possibilit√© de r√©aliser un lien avec les "collecteurs amateurs"
    - R√©fl√©chir √† quoi faire :
        - Toute l'histoire d'un magazine ?
        - D'une √©poque ?
        - Histoire de la publicit√© ?
        - Id√©e √©ditoriale ?
        - Signature de l'√©volution d'un magazine ?
        - Classifier les magazines en fonction de l'√©poque ?
    - Comment classifier tout le contenu ?
        - Extraire du texte (OCA) ou pas ? (cf. Google Vision)
    - Prochaines √©tapes :
        - Il faut explorer le site AbandonMag (https://abandonware-magazines.org/) pour explorer quelques magazines, et trouver le type de corpus que l'on souhaite.
        - Il faut ensuite r√©fl√©chir √† notre corpus, puis √† notre probl√©matique.
- Mise en place structure initiale repo.

## 2019.11.15
- "But du jeu technique" : "classifier tous les √©l√©ments d'un magazine en √©tant le plus fin possible"
    - "L'id√©e est d'avoir une organisation hi√©rarchique de classes pour aller de plus en plus finement"

## 2019.11.13
- Newcommer: Magalie Vetter, qui va nous supervier avec Yannick.
- "Une probl√©matique plus large et connexe qui pourrait peut-√™tre √™tre int√©ressante consisterait √† trouver des moyens de distinguer les diff√©rentes parties d'un magazines automatiquement par exemple"
- But du m√©moire de Magalie : "d√©tecter la publicit√© pleine page de la publicit√© encart dans les magazines de jeu vid√©o, afin de r√©cup√©rer des donn√©es quantitatives"
- Potentialit√©s :
    - "d√©tection des diff√©rentes parties d'un magazine" ?
    - L'√©volution de la pub ou de la ligne √©ditoriale sur une magazine pour toute sa dur√©e ?
    - De plusieurs magazines sur un temps r√©duit ?
    - Juste des images ?
    - Extraire et classifier les images ?
    - "√©tudier l'impact des annonceurs dans des magazines de 1988 √† 1998" (pbmt de Magalie)

## 2019.11.11
- Rencontre pr√©liminaire avec Yannick Rochat.
- Discussion des diff√©rents axes possibles.
    - Classification publicit√©s jeux vid√©o;
    - D√©tecter type d'articles;
    - Presse en g√©n√©rale;
    - DHLab: journaux ou √©criture manuscrite;
    - D√©tecter s√©quences;
    - Speedrun TAS ou pas ?
