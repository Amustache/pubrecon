{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# !pip install -e ../  # If not done yet..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pubrecon.data import DataFrame, ImagesData\n",
    "from pubrecon.model import RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "data_path = \"../data/in/\"  # Where is your input data\n",
    "work_path = \"../data/out/\"  # Where everything will be saved\n",
    "seed = 1337  # Random seed\n",
    "verbose = 1  # 0: no output; 1: normal informations; 2: e v e r y th i n g\n",
    "\n",
    "# DataFrame\n",
    "dataframe_pickle_path = os.path.join(work_path, \"dataframe.pickle\")  # Where will the DataFrame be saved\n",
    "force_preparation = True  # Do you want to bypassed the saved DataFrame\n",
    "subsamples = 512  # Number of samples to use for the DataFrame; -1: Use all of them\n",
    "\n",
    "# ImagesData\n",
    "imagesdata_pickle_path = os.path.join(work_path, 'imagesdata.pickle')  # Where will the ImagesData be saved\n",
    "number_of_results = 2500  # How many samples will selective search use\n",
    "iou_threshold = 0.85  # What is the percent of precision required\n",
    "max_samples = 30  # How many class samples do you want\n",
    "show_infos = False  # Show information for images output\n",
    "show_labels = False  # Show labels for images output\n",
    "\n",
    "# RCNN\n",
    "model_and_weights_path = \"../data/out/\"  # Where will the model and weights be saved/loaded\n",
    "loss = None  # Loss function; None: Use crossentropy\n",
    "opt = None  # Optimization function; None: Use Adame\n",
    "lr = 0.001  # Learning rate\n",
    "epochs = 10  # Number of epochs\n",
    "batch_size = 16\n",
    "split_size = 0.10  # Test/Train proportion\n",
    "checkpoint_path = os.path.join(work_path, 'checkpoint.h5')  # Where will the checkpoints be saved; None: No checkpoint (don't.)\n",
    "early_stopping = False  # Should the learning stop if no more improvment is done\n",
    "threshold = 0.80  # Threshold used for the recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = DataFrame(data_path, pickle_path=dataframe_pickle_path)\n",
    "dataframe.prepare_data(force_preparation=force_preparation, subsamples=subsamples, verbose=verbose)\n",
    "dataframe.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesdata = ImagesData(dataframe, pickle_path=imagesdata_pickle_path)\n",
    "# That part is quite long, beware!\n",
    "imagesdata.prepare_images_and_labels(number_of_results=number_of_results, iou_threshold=iou_threshold,\n",
    "                                     max_samples=max_samples, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save it for later.\n",
    "with open(imagesdata_pickle_path, 'wb') as fi:\n",
    "    pickle.dump(imagesdata, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(imagesdata_pickle_path, 'rb') as fi:\n",
    "    imagesdata = pickle.load(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 27757 samples for 33 classes.\n",
      "['edito', 'news', 'sommaire', 'dossier', 'pub_double', 'pub_jeu', 'preview', 'publicite', 'courrier', 'pub_non_jeu', 'pub_pleine_page', 'message', 'article', 'pub_produits_mag', 'logo', 'pub_texte', 'concours', 'pub_encart', 'couverture', 'icono_dessin', 'pub_image', 'background', 'ours', 'note', 'contenu_editorial', 'supplements', 'pub_services', 'test', 'soluce', 'petites_annonces', 'article_non_jeu', 'test_court', 'pub_materiel_info']\n"
     ]
    }
   ],
   "source": [
    "imagesdata.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tests: 32.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam, Nadam\n",
    "\n",
    "losses = ['categorical_crossentropy']\n",
    "optimizers = [Adam, Nadam]\n",
    "lrs = [0.001 * 2 * x for x in range(1, 5)]\n",
    "batch_sizes = [16, 32, 64, 128]\n",
    "\n",
    "num_tests = len(losses) * len(optimizers) * len(lrs) * len(batch_sizes)\n",
    "print(\"Total tests: {}.\".format(num_tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1\n",
      "<class 'keras.optimizers.Adam'> 0.002 16\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Guest/Desktop/ML-2019/project2/pubrecon/model.py:65: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  self.model = Model(input=vggmodel.input, output=predictions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Guest/.conda/envs/aaa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/5\n",
      "98/98 [==============================] - 640s 7s/step - loss: 8.0265 - acc: 0.4955 - val_loss: 7.9768 - val_acc: 0.5051\n",
      "Epoch 2/5\n",
      "98/98 [==============================] - 617s 6s/step - loss: 7.8535 - acc: 0.5128 - val_loss: 7.9144 - val_acc: 0.5090\n",
      "Epoch 3/5\n",
      "98/98 [==============================] - 615s 6s/step - loss: 7.8843 - acc: 0.5108 - val_loss: 8.0179 - val_acc: 0.5026\n",
      "Epoch 4/5\n",
      "98/98 [==============================] - 606s 6s/step - loss: 7.9563 - acc: 0.5064 - val_loss: 7.7904 - val_acc: 0.5167\n",
      "Epoch 5/5\n",
      "15/98 [===>..........................] - ETA: 5:39 - loss: 8.8650 - acc: 0.4500"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tests = []\n",
    "test = 0\n",
    "for o in tqdm(optimizers):\n",
    "    for l in tqdm(lrs, leave=False):\n",
    "        for b in tqdm(batch_sizes, leave=False):\n",
    "            test += 1\n",
    "            print(\"test {}\".format(test))\n",
    "            print(o, l, b)\n",
    "            model = RCNN(imagesdata, loss=None, opt=o, lr=l, verbose=0)\n",
    "            model.train(epochs=5, batch_size=b, split_size=split_size, checkpoint_path=None,\n",
    "                        early_stopping=None, verbose=1)\n",
    "            tests.append([o, l, b, model.history()])\n",
    "            \n",
    "            with open(\"tests.pickle\", 'wb') as fi:\n",
    "                pickle.dump(tests, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results.pickle\", 'wb') as fi:\n",
    "    pickle.dump(tests, fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
